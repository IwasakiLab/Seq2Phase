{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd292353-1b86-4fe7-9195-ac08017e8b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import matthews_corrcoef, make_scorer\n",
    "from statistics import stdev, variance, mean\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e18cfcf-7e4b-41f0-a5ec-445928a208c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, path='checkpoint_model.pth'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:  \n",
    "            self.best_score = score   \n",
    "            self.checkpoint(val_loss, model)  \n",
    "        elif score <= self.best_score:  \n",
    "            self.counter += 1   \n",
    "            if self.verbose:  \n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')   \n",
    "            if self.counter >= self.patience:  \n",
    "                self.early_stop = True\n",
    "        else:  \n",
    "            self.best_score = score  \n",
    "            self.checkpoint(val_loss, model)  \n",
    "            self.counter = 0  \n",
    "            \n",
    "    def checkpoint(self, val_loss, model):\n",
    "        if self.verbose:  \n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)  \n",
    "        self.val_loss_min = val_loss  \n",
    "        \n",
    "def training_loop(n_epochs, optimizer, model, loss, mask_train, x_train,  y_train):\n",
    "    loss=loss\n",
    "    \n",
    "    n_samples=x_train.shape[0]\n",
    "    n_val=int(n_samples*0.2)\n",
    "\n",
    "    shuffled_ind=torch.randperm(n_samples)\n",
    "\n",
    "    train_ind=shuffled_ind[:-n_val] \n",
    "    val_ind=shuffled_ind[-n_val:]\n",
    "    \n",
    "    x_val=x_train[val_ind]\n",
    "    y_val=y_train[val_ind]\n",
    "    \n",
    "    x_train=x_train[train_ind]\n",
    "    y_train=y_train[train_ind]\n",
    "    \n",
    "    x_train=x_train\n",
    "    y_train=y_train\n",
    "    \n",
    "    x_val=x_val\n",
    "    y_val=y_val\n",
    "\n",
    "    patience=10\n",
    "    earlystopping = EarlyStopping(patience=patience, verbose=False)\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        model.train()\n",
    "        \n",
    "        y_train_pred=model.forward(x_train)\n",
    "        loss_train=loss(y_train_pred, y_train)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_val_pred=model.forward(x_val)\n",
    "            loss_val=loss(y_val_pred, y_val)\n",
    "\n",
    "        earlystopping(loss_val, model) \n",
    "        if earlystopping.early_stop: \n",
    "            break\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "class FNN2(nn.Module):\n",
    "    def __init__(self, embeddings_dim=1024, dropout=0.25):\n",
    "        super(FNN2, self).__init__()\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(embeddings_dim, 32),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,2)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor, **kwargs) -> torch.Tensor:\n",
    "        o = self.linear(x)  \n",
    "        return o\n",
    "    \n",
    "\n",
    "class NN(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_epochs=500, lr=0.03):\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr = lr\n",
    "        self.model = None\n",
    "        self.optim = None\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "        n_dim = X_tensor.shape[1]\n",
    "        self.model=FNN2(embeddings_dim=n_dim)\n",
    "        self.optim = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        training_loop(\n",
    "            n_epochs=self.n_epochs,\n",
    "            optimizer=self.optim,\n",
    "            model=self.model,\n",
    "            loss=self.loss,\n",
    "            mask_train=None,\n",
    "            x_train=X_tensor,\n",
    "            y_train=y_tensor,\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float)\n",
    "            self.model.eval()\n",
    "            y_pred = self.model(X_tensor)\n",
    "            _, predicted = torch.max(y_pred, 1)\n",
    "            return predicted.numpy()\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float)\n",
    "            self.model.eval()\n",
    "            y_pred = self.model(X_tensor)\n",
    "            probas = nn.Softmax(dim=1)(y_pred)\n",
    "            return probas.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ce3878-0a02-4893-bdeb-ea9c5ee4899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_set=set()\n",
    "others_set=set()\n",
    "scaffold_set=set()\n",
    "for rec in SeqIO.parse(\"../fig1/result/drllps_client_clstr_Homo_sapiens.fasta\", \"fasta\"):\n",
    "    client_set.add(rec.id)\n",
    "for rec in SeqIO.parse(\"../fig1/result/drllps_nonllps_clstr_Homo_sapiens.fasta\", \"fasta\"):\n",
    "    others_set.add(rec.id)\n",
    "for rec in SeqIO.parse(\"../fig1/result/drllps_scaffold_clstr_Homo_sapiens.fasta\", \"fasta\"):\n",
    "    scaffold_set.add(rec.id)\n",
    "    \n",
    "mat=np.load(\"../fig2/embedding/PTT5XLU50_human.npy\", allow_pickle=True)\n",
    "mat=mat.item()\n",
    "\n",
    "list_client=[]\n",
    "list_others=[]\n",
    "list_scaffold=[]\n",
    "client_ids=[]\n",
    "scaffold_ids=[]\n",
    "nonllps_ids=[]\n",
    "for k in mat.keys():\n",
    "    if k in others_set:\n",
    "        list_others.append(mat[k])\n",
    "        nonllps_ids.append(k)\n",
    "    elif k in client_set:\n",
    "        list_client.append(mat[k])\n",
    "        client_ids.append(k)\n",
    "    elif k in scaffold_set:\n",
    "        list_scaffold.append(mat[k])\n",
    "        scaffold_ids.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8454f19e-11c6-455b-9c9f-e414c1c773ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "x_all=np.array(list_client+list_others)\n",
    "y_all=np.array([True]*len(list_client) + [False]*len(list_others))\n",
    "idx_all=np.array(client_ids+nonllps_ids)\n",
    "estimators = [\n",
    "    ('nn', NN(lr=0.01)),\n",
    "    ('rf', RandomForestClassifier(max_depth=20, max_features=\"sqrt\", class_weight=\"balanced\",n_estimators=200, n_jobs=40)),\n",
    "    ('svm', make_pipeline(StandardScaler(), SVC(class_weight=\"balanced\", probability=True, gamma=\"auto\"))),\n",
    "    ('hgboost', HistGradientBoostingClassifier(learning_rate=0.1, max_leaf_nodes=63, min_samples_leaf=80, class_weight=\"balanced\"))\n",
    "]\n",
    "cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "model_client=StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression(class_weight=\"balanced\"), n_jobs=-1, cv=cv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d29175-eaee-4b77-8c4d-c9f000c4c7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sca=np.array(list_scaffold)\n",
    "idx_sca=np.array(scaffold_ids)\n",
    "idx_cli=[]\n",
    "idx_non=[]\n",
    "cli_score_cli=[]\n",
    "cli_score_non=[]\n",
    "cli_score_sca=[]\n",
    "skf = StratifiedKFold(n_splits=10, random_state=0, shuffle=True)\n",
    "for train, test in skf.split(x_all,y_all):\n",
    "    model_client.fit(x_all[train], y_all[train])\n",
    "    x_test=x_all[test]\n",
    "    y_test=y_all[test]\n",
    "    idx_test=idx_all[test]\n",
    "    x_test_t=x_test[y_test==True]\n",
    "    x_test_f=x_test[y_test==False]\n",
    "    idx_test_t=idx_test[y_test==True]\n",
    "    idx_test_f=idx_test[y_test==False]\n",
    "    \n",
    "    y_pred_client=model_client.predict_proba(x_test_t)[:,1]\n",
    "    y_pred_non=model_client.predict_proba(x_test_f)[:,1]\n",
    "    y_pred_sca=model_client.predict_proba(x_sca)[:,1]\n",
    "    cli_score_cli.append(y_pred_client)\n",
    "    cli_score_non.append(y_pred_non)\n",
    "    cli_score_sca.append(y_pred_sca)\n",
    "    idx_cli.append(idx_test_t)\n",
    "    idx_non.append(idx_test_f)\n",
    "cli_score_cli=np.concatenate(cli_score_cli)\n",
    "cli_score_non=np.concatenate(cli_score_non)\n",
    "cli_score_sca=np.mean(np.array(cli_score_sca), axis=0)\n",
    "idx_cli=np.concatenate(idx_cli)\n",
    "idx_non=np.concatenate(idx_non)\n",
    "\n",
    "cli_score_cli={k:v for k,v in zip(idx_cli, cli_score_cli)}\n",
    "cli_score_non={k:v for k,v in zip(idx_non, cli_score_non)}\n",
    "cli_score_sca={k:v for k,v in zip(idx_sca, cli_score_sca)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47594b56-6b40-4a31-9082-036e11b30b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cli_score_cli), len(cli_score_non), len(cli_score_sca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90775b53-b5d1-4430-a687-de3d50d04fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all=np.array(list_scaffold+list_others+list_client)\n",
    "y_all=np.array([True]*len(list_scaffold) + [False]*len(list_others+list_client))\n",
    "is_client=np.array([False]*len(list_scaffold+list_others) + [True]*len(list_client))\n",
    "is_nonllps=np.array([False]*len(list_scaffold) + [True]*len(list_others) + [False]*len(list_client))\n",
    "idx_all=np.array(scaffold_ids+nonllps_ids+client_ids)\n",
    "estimators = [\n",
    "    ('nn', make_pipeline(StandardScaler(), PCA(n_components=128), NN(lr=0.05))),\n",
    "    ('rf', make_pipeline(StandardScaler(), PCA(n_components=128), RandomForestClassifier(max_depth=5, max_features=\"log2\", class_weight=\"balanced\", n_estimators=200, n_jobs=40))),\n",
    "    ('svm', make_pipeline(StandardScaler(), PCA(n_components=128), SVC(class_weight=\"balanced\", probability=True, C=1, kernel=\"rbf\", gamma=\"scale\"))),\n",
    "    ('hgboost', make_pipeline(StandardScaler(), PCA(n_components=64), HistGradientBoostingClassifier(learning_rate=0.1, max_leaf_nodes=31, min_samples_leaf=40, class_weight=\"balanced\")))\n",
    "]\n",
    "cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "model_scaffold=StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression(class_weight=\"balanced\"), n_jobs=-1, cv=cv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce27207-9a83-41ce-ba72-3a86e1e81dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "idx_sca=[]\n",
    "idx_non=[]\n",
    "idx_cli=[]\n",
    "sca_score_cli=[]\n",
    "sca_score_non=[]\n",
    "sca_score_sca=[]\n",
    "skf = StratifiedKFold(n_splits=10, random_state=0, shuffle=True)\n",
    "i=0\n",
    "for train, test in skf.split(x_all,y_all):\n",
    "    model_scaffold.fit(x_all[train], y_all[train])\n",
    "    \n",
    "    x_test=x_all[test]\n",
    "    y_test=y_all[test]\n",
    "    is_client_test=is_client[test]\n",
    "    is_nonllps_test=is_nonllps[test]\n",
    "    idx_test=idx_all[test]\n",
    "    x_test_sca=x_test[y_test==True]\n",
    "    x_test_non=x_test[is_nonllps_test==True]\n",
    "    x_test_cli=x_test[is_client_test==True]\n",
    "    idx_test_sca=idx_test[y_test==True]\n",
    "    idx_test_non=idx_test[is_nonllps_test==True]\n",
    "    idx_test_cli=idx_test[is_client_test==True]\n",
    "    \n",
    "    y_pred_sca=model_scaffold.predict_proba(x_test_sca)[:,1]\n",
    "    y_pred_non=model_scaffold.predict_proba(x_test_non)[:,1]\n",
    "    y_pred_cli=model_scaffold.predict_proba(x_test_cli)[:,1]\n",
    "    sca_score_sca.append(y_pred_sca)\n",
    "    sca_score_non.append(y_pred_non)\n",
    "    sca_score_cli.append(y_pred_cli)\n",
    "    idx_sca.append(idx_test_sca)\n",
    "    idx_non.append(idx_test_non)\n",
    "    idx_cli.append(idx_test_cli)\n",
    "    i+=1\n",
    "sca_score_sca=np.concatenate(sca_score_sca)\n",
    "sca_score_non=np.concatenate(sca_score_non)\n",
    "sca_score_cli=np.concatenate(sca_score_cli)\n",
    "idx_sca=np.concatenate(idx_sca)\n",
    "idx_non=np.concatenate(idx_non)\n",
    "idx_cli=np.concatenate(idx_cli)\n",
    "\n",
    "sca_score_cli={k:v for k,v in zip(idx_cli, sca_score_cli)}\n",
    "sca_score_non={k:v for k,v in zip(idx_non, sca_score_non)}\n",
    "sca_score_sca={k:v for k,v in zip(idx_sca, sca_score_sca)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac6e906-67c4-4223-9cb7-b9c1676b7f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sca_score_cli), len(sca_score_non), len(sca_score_sca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2703d10-bb16-4665-8458-dc0e50ccb84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score_sca=pd.DataFrame(list(sca_score_sca.values()), index=sca_score_sca.keys(), columns=['Scaffold'])\n",
    "df_score_sca['Client'] = pd.Series(cli_score_sca)\n",
    "df_score_cli=pd.DataFrame(list(sca_score_cli.values()), index=sca_score_cli.keys(), columns=['Scaffold'])\n",
    "df_score_cli['Client'] = pd.Series(cli_score_cli)\n",
    "df_score_non=pd.DataFrame(list(sca_score_non.values()), index=sca_score_non.keys(), columns=['Scaffold'])\n",
    "df_score_non['Client'] = pd.Series(cli_score_non)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c7c669-5ac8-4fc1-8fb5-fbca3d2be03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score_sca[\"Label\"]=\"Scaffold\"\n",
    "df_score_cli[\"Label\"]=\"Client\"\n",
    "df_score_non[\"Label\"]=\"Non-LLPS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db93a0a2-5f84-4faf-b00e-a7aa1ecf6477",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.scatter(x=df_score_non.loc[:,\"Client\"], y=df_score_non.loc[:,\"Scaffold\"], c=\"gray\", label=\"Non-LLPS\", s=0.5)\n",
    "plt.scatter(x=df_score_cli.loc[:,\"Client\"], y=df_score_cli.loc[:,\"Scaffold\"], c=\"orange\", label=\"Client\", s=0.8)\n",
    "plt.scatter(x=df_score_sca.loc[:,\"Client\"], y=df_score_sca.loc[:,\"Scaffold\"], c=\"b\", label=\"Scaffold\", s=2)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Client score\")\n",
    "plt.ylabel(\"Scaffold score\")\n",
    "plt.savefig(\"result/fig6a.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e172abf8-7024-486e-97d7-c20ada51e6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all=pd.concat([df_score_sca, df_score_cli, df_score_non])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec542b7-21dd-4df9-87e4-8999adeade5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "ax=sns.kdeplot(x=df_all.Client, y=df_all.Scaffold, hue=df_all.Label, \n",
    "                 common_norm=False, palette={\"Client\":\"darkorange\", \"Scaffold\":\"blueviolet\", \"Non-LLPS\":\"lightgrey\"},\n",
    "           label=[\"Non-LLPS\", \"Client\", \"Scaffold\"],\n",
    "              thresh=.33)\n",
    "sns.move_legend(ax, \"upper left\")\n",
    "plt.xlabel(\"Client score\")\n",
    "plt.ylabel(\"Scaffold score\")\n",
    "plt.xlim([-0.1,1.199])\n",
    "plt.ylim([-0.1,1.199])\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.savefig(\"result/fig6b.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46074e54-ce2a-484d-b80a-104efaffff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,.8))\n",
    "sns.kdeplot(x=df_all.Client, hue=df_all.Label, palette={\"Client\":\"darkorange\", \"Scaffold\":\"blueviolet\", \"Non-LLPS\":\"lightgrey\"},\n",
    "           common_norm=False, fill=True,legend=False)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.yticks([])\n",
    "plt.savefig(\"result/fig6bx.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcabb6eb-d021-4b2f-b189-dda5c6ee1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(.8,5))\n",
    "sns.kdeplot(y=df_all.Scaffold, hue=df_all.Label, palette={\"Client\":\"darkorange\", \"Scaffold\":\"blueviolet\", \"Non-LLPS\":\"lightgrey\"},\n",
    "           common_norm=False, fill=True,legend=False)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "plt.xticks([])\n",
    "plt.savefig(\"result/fig6by.pdf\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
