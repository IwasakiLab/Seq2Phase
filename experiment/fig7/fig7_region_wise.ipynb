{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1070900a-98d7-4b95-9796-575ffa861054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import matthews_corrcoef, make_scorer\n",
    "from statistics import stdev, variance, mean\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b500c122-986b-403a-95fd-4edaa83f85de",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_set=set()\n",
    "scaffold_set=set()\n",
    "others_set=set()\n",
    "for rec in SeqIO.parse(\"../fig1/result/drllps_client_clstr_Homo_sapiens.fasta\", \"fasta\"):\n",
    "    client_set.add(rec.id)\n",
    "for rec in SeqIO.parse(\"../fig1/result/drllps_scaffold_clstr_Homo_sapiens.fasta\", \"fasta\"):\n",
    "    scaffold_set.add(rec.id)\n",
    "for rec in SeqIO.parse(\"../fig1/result/drllps_nonllps_clstr_Homo_sapiens.fasta\", \"fasta\"):\n",
    "    others_set.add(rec.id)\n",
    "    \n",
    "mat=np.load(\"../fig2/embedding/PTT5XLU50_human.npy\", allow_pickle=True)\n",
    "mat=mat.item()\n",
    "\n",
    "list_client=[]\n",
    "list_others=[]\n",
    "list_scaffold=[]\n",
    "client_id=[]\n",
    "others_id=[]\n",
    "scaffold_id=[]\n",
    "for k in mat.keys():\n",
    "    if k in others_set:\n",
    "        list_others.append(mat[k])\n",
    "        others_id.append(k)\n",
    "    elif k in client_set:\n",
    "        list_client.append(mat[k])\n",
    "        client_id.append(k)\n",
    "    elif k in scaffold_set:\n",
    "        list_scaffold.append(mat[k])\n",
    "        scaffold_id.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1083ad24-de66-454b-8e35-ba2353dc52ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, path='checkpoint_model.pth'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:  \n",
    "            self.best_score = score   \n",
    "            self.checkpoint(val_loss, model)  \n",
    "        elif score <= self.best_score:  \n",
    "            self.counter += 1   \n",
    "            if self.verbose:  \n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')   \n",
    "            if self.counter >= self.patience:  \n",
    "                self.early_stop = True\n",
    "        else:  \n",
    "            self.best_score = score  \n",
    "            self.checkpoint(val_loss, model)  \n",
    "            self.counter = 0  \n",
    "            \n",
    "    def checkpoint(self, val_loss, model):\n",
    "        if self.verbose:  \n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)  \n",
    "        self.val_loss_min = val_loss  \n",
    "        \n",
    "def training_loop(n_epochs, optimizer, model, loss, mask_train, x_train,  y_train):\n",
    "    loss=loss\n",
    "    \n",
    "    n_samples=x_train.shape[0]\n",
    "    n_val=int(n_samples*0.2)\n",
    "\n",
    "    shuffled_ind=torch.randperm(n_samples)\n",
    "\n",
    "    train_ind=shuffled_ind[:-n_val] \n",
    "    val_ind=shuffled_ind[-n_val:]\n",
    "    \n",
    "    x_val=x_train[val_ind]\n",
    "    y_val=y_train[val_ind]\n",
    "    \n",
    "    x_train=x_train[train_ind]\n",
    "    y_train=y_train[train_ind]\n",
    "    \n",
    "    x_train=x_train\n",
    "    y_train=y_train\n",
    "    \n",
    "    x_val=x_val\n",
    "    y_val=y_val\n",
    "\n",
    "    patience=10\n",
    "    earlystopping = EarlyStopping(patience=patience, verbose=False)\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        model.train()\n",
    "        \n",
    "        y_train_pred=model.forward(x_train)\n",
    "        loss_train=loss(y_train_pred, y_train)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_val_pred=model.forward(x_val)\n",
    "            loss_val=loss(y_val_pred, y_val)\n",
    "\n",
    "        earlystopping(loss_val, model) \n",
    "        if earlystopping.early_stop: \n",
    "            break\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "class FNN2(nn.Module):\n",
    "    def __init__(self, embeddings_dim=1024, dropout=0.25):\n",
    "        super(FNN2, self).__init__()\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(embeddings_dim, 32),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,2)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor, **kwargs) -> torch.Tensor:\n",
    "        o = self.linear(x)  \n",
    "        return o\n",
    "    \n",
    "\n",
    "class NN(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_epochs=500, lr=0.03):\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr = lr\n",
    "        self.model = None\n",
    "        self.optim = None\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "        n_dim = X_tensor.shape[1]\n",
    "        self.model=FNN2(embeddings_dim=n_dim)\n",
    "        self.optim = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        training_loop(\n",
    "            n_epochs=self.n_epochs,\n",
    "            optimizer=self.optim,\n",
    "            model=self.model,\n",
    "            loss=self.loss,\n",
    "            mask_train=None,\n",
    "            x_train=X_tensor,\n",
    "            y_train=y_tensor,\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float)\n",
    "            self.model.eval()\n",
    "            y_pred = self.model(X_tensor)\n",
    "            _, predicted = torch.max(y_pred, 1)\n",
    "            return predicted.numpy()\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float)\n",
    "            self.model.eval()\n",
    "            y_pred = self.model(X_tensor)\n",
    "            probas = nn.Softmax(dim=1)(y_pred)\n",
    "            return probas.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e9bac0-e2f7-4442-b639-90b2cd29683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_sampling(x, y, idx):\n",
    "    x_ture=x[y==True]\n",
    "    x_false=x[y==False]\n",
    "    y_ture=y[y==True]\n",
    "    y_false=y[y==False]\n",
    "    idx_ture=idx[y==True]\n",
    "    idx_false=idx[y==False]\n",
    "    positive_n=len(y_ture)\n",
    "    negative_n=len(y_false)\n",
    "    random_index=np.random.randint(0,negative_n,positive_n)  \n",
    "    x_false_u=x_false[random_index]\n",
    "    y_false_u=y_false[random_index]\n",
    "    idx_false_u=idx_false[random_index]\n",
    "    return np.concatenate([x_ture, x_false_u]), np.concatenate([y_ture, y_false_u]), np.concatenate([idx_ture, idx_false_u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a4651b-9eb3-4f35-a8ca-3a1af883271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "x_all=np.array(list_client+list_others)\n",
    "y_all=np.array([True]*len(list_client) + [False]*len(list_others))\n",
    "idx_all=np.array(client_id+others_id)\n",
    "x,y,idx=under_sampling(x_all,y_all,idx_all)\n",
    "estimators = [\n",
    "    ('nn', NN(lr=0.01)),\n",
    "    ('rf', RandomForestClassifier(max_depth=20, max_features=\"sqrt\", class_weight=\"balanced\",n_estimators=200, n_jobs=40)),\n",
    "    ('svm', make_pipeline(StandardScaler(), SVC(class_weight=\"balanced\", probability=True, gamma=\"auto\"))),\n",
    "    ('hgboost', HistGradientBoostingClassifier(learning_rate=0.1, max_leaf_nodes=63, min_samples_leaf=80, class_weight=\"balanced\"))\n",
    "]\n",
    "cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "model=StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression(class_weight=\"balanced\"), n_jobs=-1, cv=cv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a34a1ca-e8d5-4ec3-a1fc-83b596c79c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
    "for train, test in skf.split(x,y):\n",
    "    model.fit(x[train], y[train])\n",
    "    \n",
    "    id_train=idx[train]\n",
    "    x_test=x[test]\n",
    "    y_test=y[test]\n",
    "    idx_test=idx[test]\n",
    "    x_test_t=x_test[y_test==True]\n",
    "    idx_test_t=idx_test[y_test==True]\n",
    "    \n",
    "    non_no_train=others_set - set(id_train)\n",
    "    x_no_train_f=[]\n",
    "    idx_no_tran_f=[]\n",
    "    for k in mat.keys():\n",
    "        if k in non_no_train:\n",
    "            x_no_train_f.append(mat[k])\n",
    "            idx_no_tran_f.append(k)\n",
    "    x_no_train_f=np.array(x_no_train_f)\n",
    "    \n",
    "    y_test_t_pred=model.predict_proba(x_test_t)\n",
    "    y_no_train_f_pred=model.predict_proba(x_no_train_f)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a41cb77-2715-4d9a-a0d5-b1aa11a49cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_pred_sorted_idx=np.argsort(y_no_train_f_pred[:,1])[::-1]\n",
    "t_pred_sorted_idx=np.argsort(y_test_t_pred[:,1])[::-1]\n",
    "non_id_sorted=np.array(idx_no_tran_f)[f_pred_sorted_idx]\n",
    "cli_id_sorted=idx_test_t[t_pred_sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c410ab-414a-49a5-bdf7-f895bf4e7b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_id_sorted=[i.split(\"|\")[1] for i in non_id_sorted]\n",
    "cli_id_sorted=[i.split(\"|\")[1] for i in cli_id_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8695e74-e7e7-4475-bd38-61161232d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_id_sorted[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0c0035-8377-48f9-af4f-3cdeedb3f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cli_id_sorted[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a885dc8e-0e7b-45c6-b8af-f42e41bb200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat=np.load(\"data/PTT5XLU50_human_aa.npy\", allow_pickle=True)\n",
    "mat=mat.item()\n",
    "\n",
    "top_n=20\n",
    "\n",
    "client_like_client_set=set(cli_id_sorted[:top_n])\n",
    "client_like_nonllps_set=set(non_id_sorted[:top_n])\n",
    "\n",
    "list_client_mat_d={}\n",
    "list_non_mat_d={}\n",
    "client_like_client_d={}\n",
    "client_like_nonllps_d={}\n",
    "\n",
    "for k in mat.keys():\n",
    "    k_id=k.split(\"|\")[1]\n",
    "    if k_id in client_like_client_set:\n",
    "        list_client_mat_d[k_id]=mat[k]\n",
    "        client_like_client_d[k_id]=k_id\n",
    "    elif k_id in client_like_nonllps_set:\n",
    "        list_non_mat_d[k_id]=mat[k]\n",
    "        client_like_nonllps_d[k_id]=k_id\n",
    "        \n",
    "list_client_mat=[list_client_mat_d[k_id] for k_id in cli_id_sorted[:top_n]]\n",
    "client_like_client=[client_like_client_d[k_id] for k_id in cli_id_sorted[:top_n]]\n",
    "list_non_mat=[list_non_mat_d[k_id] for k_id in non_id_sorted[:top_n]]\n",
    "client_like_nonllps=[client_like_nonllps_d[k_id] for k_id in non_id_sorted[:top_n]]\n",
    "del mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a70a05-16c8-4677-bb9f-ed9ba87e4289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_avg(arr, window_size):\n",
    "    if len(arr.shape) != 2:\n",
    "        raise ValueError(\"Input must be a two-dimensional array\")\n",
    "\n",
    "    if window_size > arr.shape[0]:\n",
    "        raise ValueError(\"Window size cannot be larger than the array length\")\n",
    "\n",
    "    result = np.zeros_like(arr)\n",
    "    pad_size = window_size // 2\n",
    "    for i in range(arr.shape[0]):\n",
    "        start = max(0, i - pad_size)\n",
    "        end = min(arr.shape[0], i + pad_size + 1)\n",
    "        result[i] = np.mean(arr[start:end], axis=0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4bf2a2-a14a-4684-a08a-fb07df881f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_arrs_client={}\n",
    "for mat, protein_id in zip(list_client_mat, client_like_client):\n",
    "    x_arr=sliding_window_avg(mat, 100)\n",
    "    y_arr=model.predict_proba(x_arr)\n",
    "    y_arrs_client[protein_id]=y_arr[:,1]\n",
    "    plt.axhline(y=0.5, linestyle='dashed', color='grey')\n",
    "    plt.plot(y_arr[:,1])\n",
    "    plt.ylim([0.2,0.8])\n",
    "    plt.ylabel(\"Client score\")\n",
    "    plt.xlabel(\"Sequence\")\n",
    "    plt.title(protein_id)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa45cfa8-4aae-4be7-802f-932a59515fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_arrs_nonllps={}\n",
    "for mat, protein_id in zip(list_non_mat, client_like_nonllps):\n",
    "    x_arr=sliding_window_avg(mat, 100)\n",
    "    y_arr=model.predict_proba(x_arr)\n",
    "    y_arrs_nonllps[protein_id]=y_arr[:,1]\n",
    "    plt.axhline(y=0.5, linestyle='dashed', color='grey')\n",
    "    plt.plot(y_arr[:,1])\n",
    "    plt.ylim([0.2,0.8])\n",
    "    plt.ylabel(\"Client score\")\n",
    "    plt.xlabel(\"Sequence\")\n",
    "    plt.title(protein_id)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07333339-ba64-41bf-a648-cdc2689eda41",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_list_client = sorted(y_arrs_client.items(), key=lambda x: np.mean(x[1] < 0.5), reverse=True)\n",
    "sorted_list_nonllps = sorted(y_arrs_nonllps.items(), key=lambda x: np.mean(x[1] < 0.5), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff01d98d-2b30-4a06-8238-25b668dc0bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in sorted_list_client[:3]:\n",
    "    plt.axhline(y=0.5, linestyle='dashed', color='grey')\n",
    "    plt.plot(x[1])\n",
    "    plt.ylim([0.25,0.85])\n",
    "    plt.ylabel(\"Client score\")\n",
    "    plt.xlabel(\"Sequence\")\n",
    "    plt.title(x[0])\n",
    "    plt.savefig(\"result/fig7_\"+x[0]+\".pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258bf35a-d6bd-4014-87a1-6e35a8260c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in sorted_list_nonllps[:3]:\n",
    "    plt.axhline(y=0.5, linestyle='dashed', color='grey')\n",
    "    plt.plot(x[1])\n",
    "    plt.ylim([0.25,0.85])\n",
    "    plt.ylabel(\"Client score\")\n",
    "    plt.xlabel(\"Sequence\")\n",
    "    plt.title(x[0])\n",
    "    plt.savefig(\"result/fig7_\"+x[0]+\".pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbc4536-e9ae-4cbb-95a0-8acfbc571bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in sorted_list_client[:3]:\n",
    "    indices = np.where(x[1] >= 0.5)\n",
    "    indices_1=[i+1 for i in indices[0]]\n",
    "    start=indices_1[0]\n",
    "    j=indices_1[0]\n",
    "    s=str(start)\n",
    "    for i in indices_1:\n",
    "        if i == start:\n",
    "            continue\n",
    "        if j+1 == i:\n",
    "            j=i\n",
    "            continue\n",
    "        elif start==j:\n",
    "            s=s+\"+\"+str(i)\n",
    "            start=i\n",
    "            j=i\n",
    "        else:\n",
    "            s=s+\"-\"+str(j)+\"+\"+str(i)\n",
    "            start=i\n",
    "            j=i\n",
    "    if start!=j:\n",
    "        s=s+\"-\"+str(j)\n",
    "    print(x[0])\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6417a7-2be4-4fc1-a877-d93fa64cf408",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in sorted_list_nonllps[:3]:\n",
    "    indices = np.where(x[1] >= 0.5)\n",
    "    indices_1=[i+1 for i in indices[0]]\n",
    "    start=indices_1[0]\n",
    "    j=indices_1[0]\n",
    "    s=str(start)\n",
    "    for i in indices_1:\n",
    "        if i == start:\n",
    "            continue\n",
    "        if j+1 == i:\n",
    "            j=i\n",
    "            continue\n",
    "        elif start==j:\n",
    "            s=s+\"+\"+str(i)\n",
    "            start=i\n",
    "            j=i\n",
    "        else:\n",
    "            s=s+\"-\"+str(j)+\"+\"+str(i)\n",
    "            start=i\n",
    "            j=i\n",
    "    if start!=j:\n",
    "        s=s+\"-\"+str(j)\n",
    "    print(x[0])\n",
    "    print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
