{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b08aca-a301-4507-a6a9-27f6824819f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, auc, make_scorer, matthews_corrcoef\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from statistics import stdev, mean, variance\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689e5a7b-6051-436f-8418-f3d2c8018f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, path='checkpoint_model.pth'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:  \n",
    "            self.best_score = score   \n",
    "            self.checkpoint(val_loss, model)  \n",
    "        elif score <= self.best_score:  \n",
    "            self.counter += 1   \n",
    "            if self.verbose:  \n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')   \n",
    "            if self.counter >= self.patience:  \n",
    "                self.early_stop = True\n",
    "        else:  \n",
    "            self.best_score = score  \n",
    "            self.checkpoint(val_loss, model)  \n",
    "            self.counter = 0  \n",
    "            \n",
    "    def checkpoint(self, val_loss, model):\n",
    "        if self.verbose:  \n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)  \n",
    "        self.val_loss_min = val_loss  \n",
    "        \n",
    "def training_loop(n_epochs, optimizer, model, loss, mask_train, x_train,  y_train):\n",
    "    loss=loss\n",
    "    \n",
    "    n_samples=x_train.shape[0]\n",
    "    n_val=int(n_samples*0.2)\n",
    "\n",
    "    shuffled_ind=torch.randperm(n_samples)\n",
    "\n",
    "    train_ind=shuffled_ind[:-n_val] \n",
    "    val_ind=shuffled_ind[-n_val:]\n",
    "    \n",
    "    x_val=x_train[val_ind]\n",
    "    y_val=y_train[val_ind]\n",
    "    \n",
    "    x_train=x_train[train_ind]\n",
    "    y_train=y_train[train_ind]\n",
    "    \n",
    "    x_train=x_train\n",
    "    y_train=y_train\n",
    "    \n",
    "    x_val=x_val\n",
    "    y_val=y_val\n",
    "\n",
    "    patience=10\n",
    "    earlystopping = EarlyStopping(patience=patience, verbose=False)\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        model.train()\n",
    "        \n",
    "        y_train_pred=model.forward(x_train)\n",
    "        loss_train=loss(y_train_pred, y_train)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_val_pred=model.forward(x_val)\n",
    "            loss_val=loss(y_val_pred, y_val)\n",
    "\n",
    "        earlystopping(loss_val, model) \n",
    "        if earlystopping.early_stop: \n",
    "            break\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "class FNN2(nn.Module):\n",
    "    def __init__(self, embeddings_dim=1024, dropout=0.25):\n",
    "        super(FNN2, self).__init__()\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(embeddings_dim, 32),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,2)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor, **kwargs) -> torch.Tensor:\n",
    "        o = self.linear(x)  \n",
    "        return o\n",
    "    \n",
    "\n",
    "class NN(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_epochs=500, lr=0.03):\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr = lr\n",
    "        self.model = None\n",
    "        self.optim = None\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "        n_dim = X_tensor.shape[1]\n",
    "        self.model=FNN2(embeddings_dim=n_dim)\n",
    "        self.optim = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        training_loop(\n",
    "            n_epochs=self.n_epochs,\n",
    "            optimizer=self.optim,\n",
    "            model=self.model,\n",
    "            loss=self.loss,\n",
    "            mask_train=None,\n",
    "            x_train=X_tensor,\n",
    "            y_train=y_tensor,\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float)\n",
    "            self.model.eval()\n",
    "            y_pred = self.model(X_tensor)\n",
    "            _, predicted = torch.max(y_pred, 1)\n",
    "            return predicted.numpy()\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float)\n",
    "            self.model.eval()\n",
    "            y_pred = self.model(X_tensor)\n",
    "            probas = nn.Softmax(dim=1)(y_pred)\n",
    "            return probas.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d15c11-3ccb-4923-824d-02bee01a1bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param(model_type, X, y):\n",
    "    if model_type == 'rf':\n",
    "        model = RandomForestClassifier(class_weight=\"balanced\", n_estimators=200, n_jobs=80)\n",
    "        param_grid = {'max_depth': [5, 10, 15, 20], \"max_features\": [\"log2\",\"sqrt\",None]}\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='roc_auc')\n",
    "    elif model_type == 'hgbc':\n",
    "        model = HistGradientBoostingClassifier(class_weight=\"balanced\")\n",
    "        param_grid = {'learning_rate': [0.05, 0.1, 0.2], \"max_leaf_nodes\": [15, 31, 63], \"min_samples_leaf\": [20, 40, 80]}\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='roc_auc')\n",
    "    elif model_type == 'nn':\n",
    "        model = NN()\n",
    "        param_grid = {'lr': [0.01, 0.02, 0.03, 0.04, 0.05]}\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='roc_auc')\n",
    "    if model_type == 'svm':\n",
    "        model = SVC(class_weight=\"balanced\", probability=True)\n",
    "        param_grid = {'C': [1, 10], 'kernel': ['rbf', 'sigmoid'], 'gamma':['scale', 'auto']}\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1, scoring='roc_auc')\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    return grid_search.best_params_, grid_search.best_estimator_\n",
    "\n",
    "def eval_test_data(trained_model, X_test, y_test):\n",
    "    y_pred_prob = trained_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    rocauc = roc_auc_score(y_test, y_pred_prob)\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "    prauc = auc(recall, precision)\n",
    "    \n",
    "    y_pred = trained_model.predict(X_test)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "    return {'rocauc': rocauc, 'prauc': prauc, 'mcc': mcc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417618d6-752c-4003-ad21-e946aaf9b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluation():\n",
    "    def __init__(self, x, y):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "        self.df = pd.DataFrame(columns=['Dimension', 'Model', 'Fold', 'Best_Params', 'Scores'])\n",
    "        \n",
    "    def run(self):\n",
    "        score_types=[\"rocauc\", \"prauc\", \"mcc\"]\n",
    "        temp_df_list = ['Dimension', 'Model', 'Fold', 'Best_Params', 'Scores']\n",
    "\n",
    "        with open(\"result/sca_pram_tuning_tmp.tsv\", \"w\") as f:\n",
    "            f.write('Dimension\\tModel\\tFold\\tBest_Params\\tScores')\n",
    "            f.write(\"\\n\")\n",
    "            for n_dim in [128, 64, 32, 16, 8, 4]:\n",
    "                print(\"n_dim:{}\".format(n_dim))\n",
    "    \n",
    "                for model in [\"nn\", \"hgbc\", \"rf\", \"svm\"]:\n",
    "                    print(\"model:{}\".format(model))\n",
    "                    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "                    for i, (train, test) in enumerate(cv.split(self.x, self.y)):\n",
    "                        sc=StandardScaler()\n",
    "                        pca=PCA(n_components=n_dim)\n",
    "                        scaled_x_train=sc.fit_transform(self.x[train])\n",
    "                        reduced_x_train=pca.fit_transform(scaled_x_train)\n",
    "    \n",
    "                        scaled_x_test=sc.transform(self.x[test])\n",
    "                        reduced_x_test=pca.transform(scaled_x_test)\n",
    "                        \n",
    "                        best_params, trained_model=param(model, reduced_x_train, self.y[train])\n",
    "                        scores=eval_test_data(trained_model, reduced_x_test, self.y[test])\n",
    "    \n",
    "                        row = {\n",
    "                            #'Sample': sample,\n",
    "                            'Dimension': str(n_dim),\n",
    "                            'Model': model,\n",
    "                            'Fold': i,\n",
    "                            'Best_Params': best_params,\n",
    "                            'Scores': {k: scores[k] for k in score_types}\n",
    "                        }\n",
    "                        temp_df_list.append(row)\n",
    "                        f.write(str(n_dim)+\"\\t\"+model+\"\\t\"+str(i)+\"\\t\"+str(best_params)+\"\\t\"+str({k: scores[k] for k in score_types}))\n",
    "                        f.write(\"\\n\")\n",
    "            self.df = pd.concat([self.df, pd.DataFrame(temp_df_list)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfc42d4-0290-4676-8649-4739dbb08787",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat=np.load(\"embedding/PTT5XLU50_human.npy\", allow_pickle=True).item()\n",
    "scaffold_set=set(SeqIO.index(\"../fig1/result/drllps_scaffold_clstr_Homo_sapiens.fasta\", \"fasta\").keys())\n",
    "nonllps_set=set(SeqIO.index(\"../fig1/result/drllps_nonllps_clstr_Homo_sapiens.fasta\", \"fasta\").keys())\n",
    "\n",
    "list_nonllps=[]\n",
    "list_scaffold=[]\n",
    "for k in mat.keys():\n",
    "    if k in nonllps_set:\n",
    "        list_nonllps.append(mat[k])\n",
    "    elif k in scaffold_set:\n",
    "        list_scaffold.append(mat[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86ed9bd-1327-42d0-93bb-47377656294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(list_scaffold + list_nonllps)\n",
    "y = np.array([True]*len(list_scaffold) + [False]*len(list_nonllps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1045af-9c73-4203-9bff-7f0b5e3b7d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeleval=ModelEvaluation(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aea2093-97be-4f86-8c13-b240145402bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeleval.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f142bd-2fea-4316-8457-52410b0f8ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df=pd.DataFrame(list(modeleval.df.iloc[5:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe156789-fa19-4878-a6fd-db51129b09e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"scores_scaffold_nonllps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a63c8d-87f1-4700-9925-23d48f878224",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_set=set(SeqIO.index(\"../fig1/result/drllps_client_clstr_Homo_sapiens.fasta\", \"fasta\").keys())\n",
    "\n",
    "list_client=[]\n",
    "for k in mat.keys():\n",
    "    if k in client_set:\n",
    "        list_client.append(mat[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41febcf-6fc4-415d-b863-ec39faba0669",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(list_scaffold + list_client)\n",
    "y = np.array([True]*len(list_scaffold) + [False]*len(list_client))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c7a83-7f2c-402e-bacc-d022340514bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeleval=ModelEvaluation(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a120535c-26e8-4602-9934-87dd21ca4864",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeleval.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59838966-3c13-49be-af58-7f045ee279e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df=pd.DataFrame(list(modeleval.df.iloc[5:,-1]))\n",
    "result_df.to_csv(\"scores_scaffold_client.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
