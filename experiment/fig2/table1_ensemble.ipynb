{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3d0348-373e-44c3-925a-4e059fe3d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import matthews_corrcoef, make_scorer\n",
    "from statistics import stdev, variance, mean\n",
    "from scipy.interpolate import interp1d\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbed6e2-757a-40c0-b643-7bc0140e9bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_set=set()\n",
    "others_set=set()\n",
    "for rec in SeqIO.parse(\"../fig1/result/drllps_client_clstr_Homo_sapiens.fasta\", \"fasta\"):\n",
    "    client_set.add(rec.id)\n",
    "for rec in SeqIO.parse(\"../fig1/result/drllps_nonllps_clstr_Homo_sapiens.fasta\", \"fasta\"):\n",
    "    others_set.add(rec.id)\n",
    "    \n",
    "mat=np.load(\"embedding/PTT5XLU50_human.npy\", allow_pickle=True)\n",
    "mat=mat.item()\n",
    "\n",
    "list_client=[]\n",
    "list_others=[]\n",
    "for k in mat.keys():\n",
    "    if k in others_set:\n",
    "        list_others.append(mat[k])\n",
    "    elif k in client_set:\n",
    "        list_client.append(mat[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307ae6d1-4304-49f6-b32e-33e15517fa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, path='checkpoint_model.pth'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:  \n",
    "            self.best_score = score   \n",
    "            self.checkpoint(val_loss, model)  \n",
    "        elif score <= self.best_score:  \n",
    "            self.counter += 1   \n",
    "            if self.verbose:  \n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')   \n",
    "            if self.counter >= self.patience:  \n",
    "                self.early_stop = True\n",
    "        else:  \n",
    "            self.best_score = score  \n",
    "            self.checkpoint(val_loss, model)  \n",
    "            self.counter = 0  \n",
    "            \n",
    "    def checkpoint(self, val_loss, model):\n",
    "        if self.verbose:  \n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)  \n",
    "        self.val_loss_min = val_loss  \n",
    "        \n",
    "def training_loop(n_epochs, optimizer, model, loss, mask_train, x_train,  y_train):\n",
    "    loss=loss\n",
    "    \n",
    "    n_samples=x_train.shape[0]\n",
    "    n_val=int(n_samples*0.2)\n",
    "\n",
    "    shuffled_ind=torch.randperm(n_samples)\n",
    "\n",
    "    train_ind=shuffled_ind[:-n_val] \n",
    "    val_ind=shuffled_ind[-n_val:]\n",
    "    \n",
    "    x_val=x_train[val_ind]\n",
    "    y_val=y_train[val_ind]\n",
    "    \n",
    "    x_train=x_train[train_ind]\n",
    "    y_train=y_train[train_ind]\n",
    "    \n",
    "    x_train=x_train\n",
    "    y_train=y_train\n",
    "    \n",
    "    x_val=x_val\n",
    "    y_val=y_val\n",
    "\n",
    "    patience=10\n",
    "    earlystopping = EarlyStopping(patience=patience, verbose=False)\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        model.train()\n",
    "        \n",
    "        y_train_pred=model.forward(x_train)\n",
    "        loss_train=loss(y_train_pred, y_train)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_val_pred=model.forward(x_val)\n",
    "            loss_val=loss(y_val_pred, y_val)\n",
    "\n",
    "        earlystopping(loss_val, model) \n",
    "        if earlystopping.early_stop: \n",
    "            break\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "class FNN2(nn.Module):\n",
    "    def __init__(self, embeddings_dim=1024, dropout=0.25):\n",
    "        super(FNN2, self).__init__()\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(embeddings_dim, 32),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,2)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor, **kwargs) -> torch.Tensor:\n",
    "        o = self.linear(x)  \n",
    "        return o\n",
    "    \n",
    "\n",
    "class NN(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_epochs=500, lr=0.03):\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr = lr\n",
    "        self.model = None\n",
    "        self.optim = None\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "        n_dim = X_tensor.shape[1]\n",
    "        self.model=FNN2(embeddings_dim=n_dim)\n",
    "        self.optim = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        training_loop(\n",
    "            n_epochs=self.n_epochs,\n",
    "            optimizer=self.optim,\n",
    "            model=self.model,\n",
    "            loss=self.loss,\n",
    "            mask_train=None,\n",
    "            x_train=X_tensor,\n",
    "            y_train=y_tensor,\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float)\n",
    "            self.model.eval()\n",
    "            y_pred = self.model(X_tensor)\n",
    "            _, predicted = torch.max(y_pred, 1)\n",
    "            return predicted.numpy()\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float)\n",
    "            self.model.eval()\n",
    "            y_pred = self.model(X_tensor)\n",
    "            probas = nn.Softmax(dim=1)(y_pred)\n",
    "            return probas.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7accfd8f-71a7-4f25-9667-4c3cba8aac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Display_auc():\n",
    "    def __init__(self,x:np.array, y:np.array, model):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "        self.model=model\n",
    "        \n",
    "    def run(self):\n",
    "        cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "        out_y=[]\n",
    "        out_y_proba=[]\n",
    "        scores_rocauc=[]\n",
    "        scores_prauc=[]\n",
    "        scores_mcc=[]\n",
    "        precisions=[]\n",
    "        recalls=[]\n",
    "        tprs = []\n",
    "        mean_fpr = np.linspace(0, 1, 1000)\n",
    "        \n",
    "        for train,test in cv.split(self.x, self.y):\n",
    "            #print(y[train])\n",
    "            self.model.fit(self.x[train],self.y[train])\n",
    "            y_pred_proba=self.model.predict_proba(self.x[test])[:,1]\n",
    "            y_pred=self.model.predict(self.x[test])\n",
    "            fpr, tpr, _ = roc_curve(self.y[test], y_pred_proba)\n",
    "            roc_auc=auc(fpr,tpr)\n",
    "            precision, recall, _ = precision_recall_curve(self.y[test], y_pred_proba)\n",
    "            pr_auc = auc(recall, precision)\n",
    "            mcc=matthews_corrcoef(self.y[test], y_pred)\n",
    "            \n",
    "            interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "            interp_tpr[0] = 0.0\n",
    "            tprs.append(interp_tpr)\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            scores_rocauc.append(roc_auc)\n",
    "            scores_prauc.append(pr_auc)\n",
    "            scores_mcc.append(mcc)\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "        self.mean_tpr = mean_tpr\n",
    "        self.tprs = tprs\n",
    "        self.precisions = precisions\n",
    "        self.recalls = recalls\n",
    "        self.scores_rocauc = scores_rocauc\n",
    "        self.scores_prauc = scores_prauc\n",
    "        self.scores_mcc = scores_mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdb03aa-bb66-45fb-b84a-70ee4559593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(list_client+list_others)\n",
    "y=np.array([True]*len(list_client) + [False]*len(list_others))\n",
    "estimators = [\n",
    "    ('nn', NN(lr=0.01)),\n",
    "    ('rf', RandomForestClassifier(max_depth=20, max_features=\"sqrt\", class_weight=\"balanced\",n_estimators=200, n_jobs=40)),\n",
    "    ('svm', make_pipeline(StandardScaler(), SVC(class_weight=\"balanced\", probability=True, gamma=\"auto\"))),\n",
    "    ('hgboost', HistGradientBoostingClassifier(learning_rate=0.1, max_leaf_nodes=63, min_samples_leaf=80, class_weight=\"balanced\"))\n",
    "]\n",
    "cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "model=StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression(), n_jobs=-1, cv=cv\n",
    ")\n",
    "torch.set_num_threads(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76140ee1-d09e-401c-9ed0-95d557ec13ae",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "display=Display_auc(x,y,model)\n",
    "display.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12c5a55-513c-47bf-bf31-f705acf16e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROC-AUC:{:.3f}±{:.3f}\".format(mean(display.scores_rocauc), stdev(display.scores_rocauc)))\n",
    "print(\"PR-AUC:{:.3f}±{:.3f}\".format(mean(display.scores_prauc), stdev(display.scores_prauc)))\n",
    "print(\"MCC:{:.3f}±{:.3f}\".format(mean(display.scores_mcc), stdev(display.scores_mcc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4333d29e-5f5e-43df-a0ba-1dd8313a62e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=make_pipeline(StandardScaler(), SVC(class_weight=\"balanced\", probability=True, gamma=\"auto\"))\n",
    "svm_display=Display_auc(x,y,model)\n",
    "svm_display.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7078b409-1151-46ed-8b58-d8357cd3ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROC-AUC:{:.3f}±{:.3f}\".format(mean(svm_display.scores_rocauc), stdev(svm_display.scores_rocauc)))\n",
    "print(\"PR-AUC:{:.3f}±{:.3f}\".format(mean(svm_display.scores_prauc), stdev(svm_display.scores_prauc)))\n",
    "print(\"MCC:{:.3f}±{:.3f}\".format(mean(svm_display.scores_mcc), stdev(svm_display.scores_mcc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c73607-2711-4d9d-bc8d-a50dfbfa8ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "fpr = np.linspace(0, 1, 1000)\n",
    "nda=np.array(svm_display.tprs)\n",
    "for i, tpr in enumerate(nda):\n",
    "    ax.plot(\n",
    "    fpr,\n",
    "    tpr,\n",
    "    color=\"orange\",\n",
    "    lw=1,\n",
    "    alpha=0.2\n",
    "    )\n",
    "mean_tpr = np.mean(nda, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc=mean(svm_display.scores_rocauc)\n",
    "std_auc=stdev(svm_display.scores_rocauc)\n",
    "ax.plot(\n",
    "    fpr,\n",
    "    mean_tpr,\n",
    "    color=\"orangered\",\n",
    "    label=r\"SVM (AUC = %0.3f $\\pm$ %0.3f)\" % (mean_auc, std_auc),\n",
    "    lw=2,\n",
    "    alpha=1,\n",
    ")\n",
    "\n",
    "fpr = np.linspace(0, 1, 1000)\n",
    "nda=np.array(display.tprs)\n",
    "for i, tpr in enumerate(nda):\n",
    "    ax.plot(\n",
    "    fpr,\n",
    "    tpr,\n",
    "    color=\"b\",\n",
    "    lw=1,\n",
    "    alpha=0.2\n",
    "    )\n",
    "mean_tpr = np.mean(nda, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc=mean(display.scores_rocauc)\n",
    "std_auc=stdev(display.scores_rocauc)\n",
    "ax.plot(\n",
    "    fpr,\n",
    "    mean_tpr,\n",
    "    color=\"b\",\n",
    "    label=r\"Stacked model (AUC = %0.3f $\\pm$ %0.3f)\" % (mean_auc, std_auc),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "ax.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", alpha=0.3)\n",
    "ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05]\n",
    ")\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"False positive rate\", fontsize=13)\n",
    "ax.set_ylabel(\"True positive rate\", fontsize=13)\n",
    "ax.set_title(\"Client vs. Non-LLPS\", fontsize=15)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "order = [1, 0]\n",
    "ax.legend([handles[idx] for idx in order], [labels[idx] for idx in order], loc=\"lower right\", fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c9f14a-fb25-4984-a9f1-05aad01d9144",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "all_precision = []\n",
    "mean_recall = np.linspace(0, 1, 1000)\n",
    "for precision, recall in zip(svm_display.precisions, svm_display.recalls):\n",
    "    ax.plot(\n",
    "    recall,\n",
    "    precision,\n",
    "    color=\"orange\",\n",
    "    lw=1,\n",
    "    alpha=0.2\n",
    "    )\n",
    "    interp_precision = interp1d(recall, precision)\n",
    "    resampled_precision = interp_precision(mean_recall)\n",
    "    all_precision.append(resampled_precision)\n",
    "mean_precision = np.mean(all_precision, axis=0)\n",
    "mean_auc=mean(svm_display.scores_prauc)\n",
    "std_auc=stdev(svm_display.scores_prauc)\n",
    "ax.plot(\n",
    "    mean_recall,\n",
    "    mean_precision,\n",
    "    color=\"orangered\",\n",
    "    label=r\"SVM (AUC = %0.3f $\\pm$ %0.3f)\" % (mean_auc, std_auc),\n",
    "    lw=2,\n",
    "    alpha=1,\n",
    ")\n",
    "\n",
    "all_precision = []\n",
    "mean_recall = np.linspace(0, 1, 1000)\n",
    "for precision, recall in zip(display.precisions, display.recalls):\n",
    "    ax.plot(\n",
    "    recall,\n",
    "    precision,\n",
    "    color=\"b\",\n",
    "    lw=1,\n",
    "    alpha=0.2\n",
    "    )\n",
    "    interp_precision = interp1d(recall, precision)\n",
    "    resampled_precision = interp_precision(mean_recall)\n",
    "    all_precision.append(resampled_precision)\n",
    "mean_precision = np.mean(all_precision, axis=0)\n",
    "mean_auc=mean(display.scores_prauc)\n",
    "std_auc=stdev(display.scores_prauc)\n",
    "ax.plot(\n",
    "    mean_recall,\n",
    "    mean_precision,\n",
    "    color=\"b\",\n",
    "    label=r\"Stacked model (AUC = %0.3f $\\pm$ %0.3f)\" % (mean_auc, std_auc),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05]\n",
    ")\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"Recall\", fontsize=13)\n",
    "ax.set_ylabel(\"Precision\", fontsize=13)\n",
    "ax.set_title(\"Client vs. Non-LLPS\", fontsize=15)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "order = [1, 0]\n",
    "ax.legend([handles[idx] for idx in order], [labels[idx] for idx in order], loc=\"lower right\", fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2bcdee-55de-4f55-9c3b-7ad3d40a1b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3db2d7-2ca4-4e15-9815-242b53a4fc83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w, p = wilcoxon(display.scores_prauc, svm_display.scores_prauc)\n",
    "\n",
    "print(f\"W-statistic: {w}\")\n",
    "print(f\"P-value: {p}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
