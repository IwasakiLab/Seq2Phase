{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec11cb61-43e4-4966-9cab-67a7334f25ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import esm\n",
    "from Bio import SeqIO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08761977-7150-4f84-90ad-779e0b1a5b97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data=[]\n",
    "data_long=[]\n",
    "for n, record in enumerate(SeqIO.parse(\"../../fig1/result/drllps_scaffold_clstr_Homo_sapiens.fasta\", \"fasta\")):\n",
    "    if len(record.seq)<1000:\n",
    "        data.append((record.id,record.seq))\n",
    "    else:\n",
    "        data_long.append((record.id,record.seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1b901f-ce82-43cf-a6e7-f13b6f30c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairscale.nn.data_parallel import FullyShardedDataParallel as FSDP\n",
    "from fairscale.nn.wrap import enable_wrap, wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ac0725-99a7-4f5f-b22a-84a87beb509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the distributed world with world_size 1\n",
    "url = \"tcp://localhost:23456\"\n",
    "torch.distributed.init_process_group(backend=\"nccl\", init_method=url, world_size=1, rank=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a89a5e-0bb3-4c6d-9b65-10be06fdc8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"esm2_t36_3B_UR50D\"\n",
    "model_data, regression_data = esm.pretrained._download_model_and_regression_data(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a246ec-f49c-435d-a727-2bd76f95f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model with FSDP wrapper\n",
    "fsdp_params = dict(\n",
    "    mixed_precision=True,\n",
    "    flatten_parameters=True,\n",
    "    state_dict_device=torch.device(\"cpu\"),  # reduce GPU mem usage\n",
    "    cpu_offload=True,  # enable cpu offloading\n",
    ")\n",
    "with enable_wrap(wrapper_cls=FSDP, **fsdp_params):\n",
    "    model, vocab = esm.pretrained.load_model_and_alphabet_core(\n",
    "        model_name, model_data, regression_data\n",
    "    )\n",
    "    batch_converter = vocab.get_batch_converter()\n",
    "    model.eval()\n",
    "\n",
    "    # Wrap each layer in FSDP separately\n",
    "    for name, child in model.named_children():\n",
    "        if name == \"layers\":\n",
    "            for layer_name, layer in child.named_children():\n",
    "                wrapped_layer = wrap(layer)\n",
    "                setattr(child, layer_name, wrapped_layer)\n",
    "    model = wrap(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a60f624-4034-4715-a75c-e26b7b9ba025",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "batch_tokens = batch_tokens.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f1d924-1605-4ac6-8da9-ea2cd52e0490",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for i in range(batch_tokens.shape[0]):\n",
    "    with torch.no_grad():\n",
    "        results.append(model(batch_tokens[i][None], repr_layers=[36], return_contacts=True)[\"representations\"][36])\n",
    "    if (i+1)%10==0:\n",
    "        print(i+1, \"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1282deb0-8b25-403d-8022-bd12d9acf776",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_representations = []\n",
    "for i, (_, seq) in enumerate(data):\n",
    "    sequence_representations.append(results[i][0, 1 : len(seq) + 1].mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c586144-dde7-425f-8147-261f44a54bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output={x:y.cpu().numpy() for x,y in zip(batch_labels,sequence_representations)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda2004-14d2-4c82-874a-5c3466c0fdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save(\"../esm2_3b_human_scaffold_short.npy\", output) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
